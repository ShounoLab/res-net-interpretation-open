{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import input2image\n",
    "from utils import plots\n",
    "\n",
    "from my_model import get_ilsvrc2012\n",
    "from utils.load_model import get_model\n",
    "\n",
    "from utils.tensortracker import TensorTracker\n",
    "\n",
    "from utils.performance_model import measure_performance\n",
    "\n",
    "from utils.config import dict_from_config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\n",
    "    (\"resnet34-skip4\", \"resnet\"),\n",
    "    (\"resnet34-skip\", \"resnet34-1\"),\n",
    "    (\"resnet34-skip2\", \"resnet34-2\"),\n",
    "    (\"resnet34-skip3\", \"resnet34-3\"),\n",
    "    (\"resnet34-plain4\", \"plainnet\"),\n",
    "    (\"resnet34-plain\", \"plainnet34-1\"),\n",
    "    (\"resnet34-plain2\", \"plainnet34-2\"),\n",
    "    (\"resnet34-plain3\", \"plainnet34-3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_root = \"/data2/genta/resnet/analysis/\"\n",
    "# rf_root = \"/mnt/nas3/lab_member_directories/2021_genta/resnet/e_receptive_field/\"\n",
    "rf_root = \"/mnt/nas5/lab_member_directories/2021_genta/resnet/e_receptive_field/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"20201216/\"\n",
    "numberinclass = {}\n",
    "in_path = os.path.join(in_dir, \"data_resnets.pkl\")\n",
    "with open(in_path, \"rb\") as f:\n",
    "    numberinclass[\"resnet\"] = pickle.load(f)\n",
    "in_path = os.path.join(in_dir, \"data_plainnets.pkl\")\n",
    "with open(in_path, \"rb\") as f:\n",
    "    numberinclass[\"plainnet\"] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200409_resnet34', 'resnet34-skip_', 'resnet34-skip2_', 'resnet34-skip3_']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberinclass[\"resnet\"][\"model_names\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resnet34-plain4', 'resnet34-plain', 'resnet34-plain2', 'resnet34-plain3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numberinclass[\"plainnet\"][\"model_keys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelCutter(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.original_weights = {}\n",
    "    \n",
    "    def add_weights(self, name, weight):\n",
    "        with torch.no_grad():\n",
    "            if name not in self.original_weights:\n",
    "                self.original_weights[name] = weight.clone()\n",
    "                \n",
    "                \n",
    "    def set_original_all_weights(self):\n",
    "        with torch.no_grad():\n",
    "            for name in self.original_weights:\n",
    "                layer_name = name.split(\".\")[0]\n",
    "                self.set_original_weights(layer_name)\n",
    "                \n",
    "    def set_original_weights(self, layer_name):\n",
    "        with torch.no_grad():\n",
    "            if layer_name == \"fc\":\n",
    "                key = \"{}.weight\".format(layer_name)\n",
    "                model.fc.weight.data = self.original_weights[key].data.clone()\n",
    "                key = \"{}.bias\".format(layer_name)\n",
    "                model.fc.bias.data = self.original_weights[key].data.clone()\n",
    "            else:\n",
    "                raise ValueError(layer_name)\n",
    "\n",
    "    def cut_channel_output(self, layer_name, ch):\n",
    "        with torch.no_grad():\n",
    "            if layer_name == \"fc\":\n",
    "                weight = self.model.fc.weight\n",
    "                zeros = torch.zeros_like(weight[:, ch])\n",
    "                self.add_weights(\"fc.weight\", weight)\n",
    "                self.model.fc.weight[:, ch] = zeros\n",
    "                bias = self.model.fc.bias\n",
    "                zeros = torch.zeros_like(bias[ch])\n",
    "                self.add_weights(\"fc.bias\", bias)\n",
    "                self.model.fc.bias[ch] = zeros\n",
    "            else:\n",
    "                raise ValueError(layer_name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m_key = \"resnet\"\n",
    "model = get_model(numberinclass[m_key][\"model_keys\"][0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch_cutter = ChannelCutter(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch = 0\n",
    "ch_cutter.cut_channel_output(\"fc\", ch)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch_cutter.model.fc.weight[:, ch].sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch_cutter.model.fc.bias[ch].sum()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch_cutter.set_original_all_weights()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch_cutter.original_weights[\"fc.weight\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ch_cutter.model.fc.weight[:, ch].sum(), ch_cutter.model.fc.bias[ch].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.performance_model import measure_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_ilsvrc2012(mode=\"test\")\n",
    "batch_size = 512\n",
    "gpu = 1\n",
    "\n",
    "channelcut_performances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genta/.pyenv/versions/dlb2-pytorch/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 2min 58s, sys: 3min 17s, total: 9h 6min 16s\n",
      "Wall time: 1h 3min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m_key = \"resnet\"\n",
    "\n",
    "n_sample = 5\n",
    "model_i = 0\n",
    "block_id = 2\n",
    "key_layer = \"layer4\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "model = get_model(target_numberinclass[\"model_keys\"][model_i])\n",
    "ch_cutter = ChannelCutter(model)\n",
    "\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "\n",
    "sorted_channels = np.argsort(target_unique_lens)[::-1]\n",
    "\n",
    "channelcut_performances[m_key] = {}\n",
    "\n",
    "ch_cutter.set_original_all_weights()\n",
    "channelcut_performances[m_key][-1] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)\n",
    "\n",
    "for ch in sorted_channels[:n_sample]:\n",
    "    ch_cutter.set_original_all_weights()\n",
    "    ch_cutter.cut_channel_output(\"fc\", ch)\n",
    "    channelcut_performances[m_key][ch] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)\n",
    "\n",
    "for ch in sorted_channels[-n_sample:]:\n",
    "    ch_cutter.set_original_all_weights()\n",
    "    ch_cutter.cut_channel_output(\"fc\", ch)\n",
    "    channelcut_performances[m_key][ch] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch206, count:051, loss 5.00900E-04, top1 acc -0.032\n",
      "ch428, count:045, loss 1.13209E-03, top1 acc -0.065\n",
      "ch212, count:045, loss 7.01139E-04, top1 acc -0.038\n",
      "ch467, count:043, loss 1.66859E-03, top1 acc -0.050\n",
      "ch435, count:042, loss 1.75840E-03, top1 acc -0.067\n",
      "ch081, count:009, loss 1.64681E-03, top1 acc -0.040\n",
      "ch430, count:008, loss 2.45062E-03, top1 acc -0.091\n",
      "ch048, count:008, loss 2.61768E-03, top1 acc -0.012\n",
      "ch506, count:007, loss 2.91511E-03, top1 acc -0.068\n",
      "ch415, count:007, loss 4.63297E-03, top1 acc -0.140\n"
     ]
    }
   ],
   "source": [
    "target_numberinclass = numberinclass[m_key]\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "for ch, data in channelcut_performances[m_key].items():\n",
    "    if ch < 0:\n",
    "        continue\n",
    "    tmp_data0 = channelcut_performances[m_key][-1][0]\n",
    "    tmp_data = data[0]\n",
    "    print(\"ch{:003}, count:{:03}, loss {:.5E}, top1 acc {:.3f}\".format(\n",
    "        ch, target_unique_lens[ch], tmp_data[0].mean() - tmp_data0[0].mean(), tmp_data[1].mean() - tmp_data0[1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9h 3min 36s, sys: 3min 12s, total: 9h 6min 49s\n",
      "Wall time: 1h 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m_key = \"plainnet\"\n",
    "\n",
    "n_sample = 5\n",
    "model_i = 0\n",
    "block_id = 2\n",
    "key_layer = \"layer4\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "model = get_model(target_numberinclass[\"model_keys\"][model_i])\n",
    "ch_cutter = ChannelCutter(model)\n",
    "\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "\n",
    "sorted_channels = np.argsort(target_unique_lens)[::-1]\n",
    "\n",
    "channelcut_performances[m_key] = {}\n",
    "\n",
    "ch_cutter.set_original_all_weights()\n",
    "channelcut_performances[m_key][-1] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)\n",
    "\n",
    "for ch in sorted_channels[:n_sample]:\n",
    "    ch_cutter.set_original_all_weights()\n",
    "    ch_cutter.cut_channel_output(\"fc\", ch)\n",
    "    channelcut_performances[m_key][ch] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)\n",
    "\n",
    "for ch in sorted_channels[-n_sample:]:\n",
    "    ch_cutter.set_original_all_weights()\n",
    "    ch_cutter.cut_channel_output(\"fc\", ch)\n",
    "    channelcut_performances[m_key][ch] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch466, count:040, loss 2.57773E-03, top1 acc -0.098\n",
      "ch037, count:038, loss 2.31040E-03, top1 acc 0.002\n",
      "ch089, count:038, loss 5.20002E-04, top1 acc 0.002\n",
      "ch104, count:038, loss 1.74673E-03, top1 acc -0.035\n",
      "ch441, count:037, loss 9.78314E-04, top1 acc -0.046\n",
      "ch496, count:007, loss 3.05658E-03, top1 acc -0.028\n",
      "ch218, count:007, loss 2.48525E-03, top1 acc -0.039\n",
      "ch375, count:007, loss 2.04332E-03, top1 acc -0.073\n",
      "ch197, count:007, loss 3.98087E-03, top1 acc 0.017\n",
      "ch209, count:006, loss 2.12089E-03, top1 acc -0.029\n"
     ]
    }
   ],
   "source": [
    "target_numberinclass = numberinclass[m_key]\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "for ch, data in channelcut_performances[m_key].items():\n",
    "    if ch < 0:\n",
    "        continue\n",
    "    tmp_data0 = channelcut_performances[m_key][-1][0]\n",
    "    tmp_data = data[0]\n",
    "    print(\"ch{:003}, count:{:03}, loss {:.5E}, top1 acc {:.3f}\".format(\n",
    "        ch, target_unique_lens[ch], tmp_data[0].mean() - tmp_data0[0].mean(), tmp_data[1].mean() - tmp_data0[1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch206, count:051, loss 5.00900E-04, top1 acc -0.032\n",
      "ch428, count:045, loss 1.13209E-03, top1 acc -0.065\n",
      "ch212, count:045, loss 7.01139E-04, top1 acc -0.038\n",
      "ch467, count:043, loss 1.66859E-03, top1 acc -0.050\n",
      "ch435, count:042, loss 1.75840E-03, top1 acc -0.067\n",
      "ch081, count:009, loss 1.64681E-03, top1 acc -0.040\n",
      "ch430, count:008, loss 2.45062E-03, top1 acc -0.091\n",
      "ch048, count:008, loss 2.61768E-03, top1 acc -0.012\n",
      "ch506, count:007, loss 2.91511E-03, top1 acc -0.068\n",
      "ch415, count:007, loss 4.63297E-03, top1 acc -0.140\n"
     ]
    }
   ],
   "source": [
    "m_key = \"resnet\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "for ch, data in channelcut_performances[m_key].items():\n",
    "    if ch < 0:\n",
    "        continue\n",
    "    tmp_data0 = channelcut_performances[m_key][-1][0]\n",
    "    tmp_data = data[0]\n",
    "    print(\"ch{:003}, count:{:03}, loss {:.5E}, top1 acc {:.3f}\".format(\n",
    "        ch, target_unique_lens[ch], tmp_data[0].mean() - tmp_data0[0].mean(), tmp_data[1].mean() - tmp_data0[1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelcut_performances_cum = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genta/.pyenv/versions/dlb2-pytorch/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 26min 19s, sys: 1min 12s, total: 3h 27min 32s\n",
      "Wall time: 24min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m_key = \"resnet\"\n",
    "\n",
    "n_sample = 5\n",
    "model_i = 0\n",
    "block_id = 2\n",
    "key_layer = \"layer4\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "model = get_model(target_numberinclass[\"model_keys\"][model_i])\n",
    "ch_cutter = ChannelCutter(model)\n",
    "\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "\n",
    "sorted_channels = np.argsort(target_unique_lens)[::-1]\n",
    "\n",
    "channelcut_performances_cum[m_key] = {}\n",
    "\n",
    "for cnt, ch in enumerate(sorted_channels[:n_sample]):\n",
    "    ch_cutter.cut_channel_output(\"fc\", ch)\n",
    "    if cnt == 0:\n",
    "        continue\n",
    "    channelcut_performances_cum[m_key][ch] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 21min 3s, sys: 1min 5s, total: 3h 22min 9s\n",
      "Wall time: 23min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "m_key = \"plainnet\"\n",
    "\n",
    "n_sample = 5\n",
    "model_i = 0\n",
    "block_id = 2\n",
    "key_layer = \"layer4\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "model = get_model(target_numberinclass[\"model_keys\"][model_i])\n",
    "ch_cutter = ChannelCutter(model)\n",
    "\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "\n",
    "sorted_channels = np.argsort(target_unique_lens)[::-1]\n",
    "\n",
    "channelcut_performances_cum[m_key] = {}\n",
    "\n",
    "for cnt, ch in enumerate(sorted_channels[:n_sample]):\n",
    "    ch_cutter.cut_channel_output(\"fc\", ch)\n",
    "    if cnt == 0:\n",
    "        continue\n",
    "    channelcut_performances_cum[m_key][ch] = measure_performance(ch_cutter.model, dataset, batch_size=batch_size, gpu=gpu, with_acts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 466, 37, 89, 104, 441, 496, 218, 375, 197, 209]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(channelcut_performances[m_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_key = \"resnet\"\n",
    "for cnt, ch in enumerate(channelcut_performances[m_key]):\n",
    "    if cnt > 1:\n",
    "        break\n",
    "    channelcut_performances_cum[m_key][ch] = channelcut_performances[m_key][ch]\n",
    "    \n",
    "m_key = \"plainnet\"\n",
    "for cnt, ch in enumerate(channelcut_performances[m_key]):\n",
    "    if cnt > 1:\n",
    "        break\n",
    "    channelcut_performances_cum[m_key][ch] = channelcut_performances[m_key][ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37, 89, 104, 441, -1, 466]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(channelcut_performances_cum[m_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch206, count:051, loss 5.00900E-04, top1 acc -0.032\n",
      "ch428, count:045, loss 1.58781E-03, top1 acc -0.123\n",
      "ch212, count:045, loss 2.15097E-03, top1 acc -0.147\n",
      "ch467, count:043, loss 3.76409E-03, top1 acc -0.157\n",
      "ch435, count:042, loss 5.56130E-03, top1 acc -0.192\n"
     ]
    }
   ],
   "source": [
    "m_key = \"resnet\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "sorted_channels = np.argsort(target_unique_lens)[::-1]\n",
    "for cnt, ch in enumerate(sorted_channels):\n",
    "    if cnt >= len(channelcut_performances_cum[m_key]) - 1:\n",
    "        break\n",
    "    data = channelcut_performances_cum[m_key][ch]\n",
    "    tmp_data0 = channelcut_performances_cum[m_key][-1][0]\n",
    "    tmp_data = data[0]\n",
    "    print(\"ch{:003}, count:{:03}, loss {:.5E}, top1 acc {:.3f}\".format(\n",
    "        ch, target_unique_lens[ch], tmp_data[0].mean() - tmp_data0[0].mean(), tmp_data[1].mean() - tmp_data0[1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch466, count:040, loss 2.57773E-03, top1 acc -0.098\n",
      "ch037, count:038, loss 5.06831E-03, top1 acc -0.151\n",
      "ch089, count:038, loss 5.58058E-03, top1 acc -0.153\n",
      "ch104, count:038, loss 6.93865E-03, top1 acc -0.192\n",
      "ch441, count:037, loss 7.68064E-03, top1 acc -0.216\n"
     ]
    }
   ],
   "source": [
    "m_key = \"plainnet\"\n",
    "target_numberinclass = numberinclass[m_key]\n",
    "key = \"{}-{}-{}\".format(target_numberinclass[\"model_names\"][model_i], key_layer, block_id)\n",
    "target_unique_lens = target_numberinclass[\"data\"][key][2]\n",
    "sorted_channels = np.argsort(target_unique_lens)[::-1]\n",
    "for cnt, ch in enumerate(sorted_channels):\n",
    "    if cnt >= len(channelcut_performances_cum[m_key]) - 1:\n",
    "        break\n",
    "    data = channelcut_performances_cum[m_key][ch]\n",
    "    tmp_data0 = channelcut_performances_cum[m_key][-1][0]\n",
    "    tmp_data = data[0]\n",
    "    print(\"ch{:003}, count:{:03}, loss {:.5E}, top1 acc {:.3f}\".format(\n",
    "        ch, target_unique_lens[ch], tmp_data[0].mean() - tmp_data0[0].mean(), tmp_data[1].mean() - tmp_data0[1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"20201217\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(out_dir, \"channelcut_performances.pkl\")\n",
    "with open(out_path, \"wb\") as f:\n",
    "    pickle.dump(channelcut_performances, f)\n",
    "    \n",
    "out_path = os.path.join(out_dir, \"channelcut_performances_cum.pkl\")\n",
    "with open(out_path, \"wb\") as f:\n",
    "    pickle.dump(channelcut_performances_cum, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1581143749003509"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelcut_performances[\"resnet\"][-1][0][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.158615274696934"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelcut_performances[\"resnet\"][206][0][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.327886345435162"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelcut_performances[\"plainnet\"][-1][0][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.327886345435162"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channelcut_performances[\"plainnet\"][-1][0][0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.4292357308524"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 1 acc\n",
    "channelcut_performances[\"resnet\"][-1][0][1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67.67027679754763"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 1 acc\n",
    "channelcut_performances[\"plainnet\"][-1][0][1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.4292357308524"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 1 acc\n",
    "channelcut_performances[\"resnet\"][-1][0][1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlb2-pytorch",
   "language": "python",
   "name": "dlb2-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
